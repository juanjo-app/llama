# Ejemplos de C贸digo - Ollama

Esta carpeta contiene ejemplos pr谩cticos de uso de Ollama con Llama.

##  Contenido

### Ejemplos B谩sicos
- `simple_chat.py` - Chatbot simple en terminal
- `streaming_response.py` - Respuestas con streaming
- `model_info.py` - Informaci贸n de modelos

### Ejemplos Intermedios
- `custom_personality.py` - Chatbot con personalidad personalizada
- `conversation_memory.py` - Chat con memoria de conversaci贸n
- `file_processor.py` - Procesamiento de archivos de texto

### Ejemplos Avanzados
- `api_server.py` - Servidor API con FastAPI
- `batch_processing.py` - Procesamiento en lotes
- `model_comparison.py` - Comparaci贸n de modelos

##  Comenzar

### Prerequisitos

```bash
# Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Descargar modelo
ollama pull llama3.2:3b

# Instalar dependencias Python
pip install -r requirements.txt
```

### Ejecutar Ejemplos

```bash
# Ejemplo b谩sico
python simple_chat.py

# Con modelo espec铆fico
python simple_chat.py --model llama3.1:8b

# Servidor API
python api_server.py
```

##  Documentaci贸n

Para m谩s informaci贸n, consulta la [documentaci贸n completa](../../docs/README.md).
