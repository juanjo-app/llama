# Cap铆tulo 2: Configuraci贸n del Entorno

##  Contenido

1. [Instalaci贸n de Ollama](#instalaci贸n-de-ollama)
2. [Descarga de Modelos](#descarga-de-modelos)
3. [Configuraci贸n de Python](#configuraci贸n-de-python)
4. [Herramientas de Desarrollo](#herramientas-de-desarrollo)
5. [Verificaci贸n de la Instalaci贸n](#verificaci贸n-de-la-instalaci贸n)

---

## Instalaci贸n de Ollama

Ollama es la forma m谩s sencilla de ejecutar Llama y otros LLMs localmente.

### Windows

```bash
# Descarga el instalador desde ollama.ai
# O usa winget
winget install Ollama.Ollama
```

### macOS

```bash
# Descarga desde ollama.ai
# O usa Homebrew
brew install ollama
```

### Linux

```bash
# Instalaci贸n con script oficial
curl -fsSL https://ollama.ai/install.sh | sh

# O instalaci贸n manual
# Descarga desde GitHub releases
wget https://github.com/ollama/ollama/releases/latest/download/ollama-linux-amd64
sudo install -o0 -g0 -m755 ollama-linux-amd64 /usr/local/bin/ollama
```

### Verificaci贸n de Ollama

```bash
# Verifica la instalaci贸n
ollama --version

# Inicia el servicio (si no se inici贸 autom谩ticamente)
ollama serve
```

## Descarga de Modelos

### Modelos Llama Recomendados

```bash
# Modelo peque帽o para comenzar (1B par谩metros)
ollama pull llama3.2:1b

# Modelo medio, buen balance (3B par谩metros)
ollama pull llama3.2:3b

# Modelo est谩ndar (8B par谩metros) - RECOMENDADO
ollama pull llama3.1:8b

# Modelo grande para tareas complejas (70B par谩metros)
ollama pull llama3.1:70b
```

### Lista de Modelos Disponibles

```bash
# Ver modelos instalados
ollama list

# Buscar modelos disponibles
ollama search llama

# Ver informaci贸n de un modelo
ollama show llama3.1:8b
```

### Espacio en Disco Requerido

| Modelo | Cuantizaci贸n | Tama帽o Aprox. |
|--------|--------------|---------------|
| llama3.2:1b | Q4 | ~1GB |
| llama3.2:3b | Q4 | ~2GB |
| llama3.1:8b | Q4 | ~4.7GB |
| llama3.1:8b | Q8 | ~8.5GB |
| llama3.1:70b | Q4 | ~40GB |

## Configuraci贸n de Python

### Instalaci贸n de Python

```bash
# Verifica si Python est谩 instalado
python --version
# o
python3 --version

# Debe ser Python 3.8 o superior
```

### Entorno Virtual

```bash
# Crea un entorno virtual
python -m venv venv

# Activa el entorno virtual
# En Windows:
venv\Scripts\activate

# En macOS/Linux:
source venv/bin/activate
```

### Instalaci贸n de Dependencias

```bash
# Actualiza pip
pip install --upgrade pip

# Instala bibliotecas esenciales
pip install ollama
pip install langchain
pip install langchain-community
pip install chromadb
pip install sentence-transformers
pip install requests
pip install python-dotenv
```

### Archivo requirements.txt

Crea un archivo `requirements.txt`:

```txt
ollama>=0.1.0
langchain>=0.1.0
langchain-community>=0.0.20
chromadb>=0.4.0
sentence-transformers>=2.3.0
requests>=2.31.0
python-dotenv>=1.0.0
fastapi>=0.109.0
uvicorn>=0.27.0
```

Instala con:
```bash
pip install -r requirements.txt
```

## Herramientas de Desarrollo

### Editor de C贸digo

Recomendaciones:
- **VS Code**: Con extensiones Python, Jupyter
- **PyCharm**: Edici贸n Community gratuita
- **Cursor**: AI-powered IDE

### VS Code - Extensiones Recomendadas

```json
{
  "recommendations": [
    "ms-python.python",
    "ms-python.vscode-pylance",
    "ms-toolsai.jupyter",
    "github.copilot",
    "esbenp.prettier-vscode"
  ]
}
```

### Git (Opcional pero Recomendado)

```bash
# Verifica instalaci贸n
git --version

# Configura tu identidad
git config --global user.name "Tu Nombre"
git config --global user.email "tu@email.com"
```

### Docker (Opcional)

Para despliegues y aislamiento:

```bash
# Verifica instalaci贸n
docker --version

# Imagen b谩sica con Ollama
docker pull ollama/ollama
```

## Verificaci贸n de la Instalaci贸n

### Test 1: Ollama CLI

```bash
# Prueba r谩pida de generaci贸n
ollama run llama3.2:1b "驴Cu谩l es la capital de M茅xico?"

# Debe responder: "La capital de M茅xico es Ciudad de M茅xico..."
```

### Test 2: Python + Ollama

Crea `test_ollama.py`:

```python
import ollama

# Test b谩sico
response = ollama.chat(
    model='llama3.2:1b',
    messages=[{
        'role': 'user',
        'content': '驴Cu谩l es la capital de M茅xico?'
    }]
)

print(response['message']['content'])
```

Ejecuta:
```bash
python test_ollama.py
```

### Test 3: Servidor API

```bash
# En una terminal, inicia Ollama
ollama serve

# En otra terminal, prueba la API
curl http://localhost:11434/api/generate -d '{
  "model": "llama3.2:1b",
  "prompt": "驴Cu谩l es la capital de M茅xico?",
  "stream": false
}'
```

### Test 4: Recursos del Sistema

```python
# test_resources.py
import psutil
import platform

print(f"Sistema Operativo: {platform.system()}")
print(f"CPU: {platform.processor()}")
print(f"N煤cleos CPU: {psutil.cpu_count()}")
print(f"RAM Total: {psutil.virtual_memory().total / (1024**3):.2f} GB")
print(f"RAM Disponible: {psutil.virtual_memory().available / (1024**3):.2f} GB")

# Agrega a requirements.txt: psutil
```

## Soluci贸n de Problemas Comunes

### Problema: "Ollama not found"

```bash
# Verifica que Ollama est茅 en el PATH
echo $PATH  # macOS/Linux
echo %PATH%  # Windows

# Reinicia la terminal despu茅s de instalar
```

### Problema: "Out of Memory"

```bash
# Usa un modelo m谩s peque帽o
ollama pull llama3.2:1b

# O aumenta swap en Linux
sudo fallocate -l 8G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

### Problema: "Connection refused"

```bash
# Aseg煤rate de que Ollama est茅 ejecut谩ndose
ollama serve

# Verifica el puerto
lsof -i :11434  # macOS/Linux
netstat -ano | findstr :11434  # Windows
```

##  Ejercicio Pr谩ctico

1. **Instalaci贸n Completa**:
   - Instala Ollama
   - Descarga al menos 2 modelos diferentes
   - Configura un entorno virtual Python
   - Instala todas las dependencias

2. **Prueba de Rendimiento**:
   - Mide el tiempo de respuesta de diferentes modelos
   - Compara cuantizaciones (Q4 vs Q8)

3. **Script de Verificaci贸n**:
   - Crea un script que verifique todas las dependencias
   - Debe mostrar versiones y confirmar que todo funciona

---

##  Recursos de Instalaci贸n

- [Ollama Documentation](https://github.com/ollama/ollama)
- [Python Official](https://www.python.org/)
- [Docker Documentation](https://docs.docker.com/)

## ★ Siguiente Paso

Contin煤a con el [Cap铆tulo 3: Construcci贸n de Aplicaciones](./04-capitulo-3.md) para crear tu primera aplicaci贸n.
