# GuÃ­a de Inicio RÃ¡pido ğŸš€

Bienvenido al workshop "Build Your Own AI Stack con Llama". Esta guÃ­a te ayudarÃ¡ a empezar en minutos.

## â±ï¸ Tiempo Estimado

- **Setup bÃ¡sico**: 10-15 minutos
- **Primer ejemplo**: 5 minutos
- **ExploraciÃ³n completa**: 1-2 horas

## ğŸ“‹ Antes de Empezar

### Verificar Requisitos

```bash
# Python (debe ser 3.8+)
python3 --version

# Espacio en disco (necesitas al menos 10GB libres)
df -h

# Memoria RAM (recomendado 8GB+)
# Linux: free -h
# macOS: system_profiler SPHardwareDataType | grep Memory
# Windows: systeminfo | find "Total Physical Memory"
```

## ğŸ› ï¸ InstalaciÃ³n Paso a Paso

### Paso 1: Clonar el Repositorio

```bash
# OpciÃ³n A: HTTPS
git clone https://github.com/majorjuanjo/llama.git

# OpciÃ³n B: SSH
git clone git@github.com:majorjuanjo/llama.git

# Entrar al directorio
cd llama
```

### Paso 2: Instalar Ollama

#### macOS

```bash
# OpciÃ³n A: Descarga directa
# Ve a https://ollama.ai y descarga el instalador

# OpciÃ³n B: Homebrew
brew install ollama
```

#### Linux

```bash
# Script oficial de instalaciÃ³n
curl -fsSL https://ollama.ai/install.sh | sh

# Verificar instalaciÃ³n
ollama --version
```

#### Windows

```bash
# Descarga el instalador desde https://ollama.ai
# Ejecuta el instalador y sigue las instrucciones

# Verifica en PowerShell o CMD
ollama --version
```

### Paso 3: Descargar un Modelo

```bash
# Modelo pequeÃ±o para comenzar (recomendado)
ollama pull llama3.2:3b

# Alternativas segÃºn tu hardware:
# 1GB RAM: ollama pull llama3.2:1b
# 8GB RAM: ollama pull llama3.1:8b
# 48GB RAM: ollama pull llama3.1:70b

# Verificar modelos descargados
ollama list
```

### Paso 4: Configurar Python

```bash
# Crear entorno virtual (recomendado)
python3 -m venv venv

# Activar entorno virtual
# macOS/Linux:
source venv/bin/activate

# Windows:
venv\Scripts\activate

# Actualizar pip
pip install --upgrade pip
```

### Paso 5: Instalar Dependencias

```bash
# Para ejemplos de Ollama
cd code/ollama
pip install -r requirements.txt

# Para ejemplos de RAG
cd ../rag
pip install -r requirements.txt

# Volver al directorio raÃ­z
cd ../..
```

## âœ… Verificar InstalaciÃ³n

### Test 1: Ollama CLI

```bash
# Prueba rÃ¡pida en terminal
ollama run llama3.2:3b "Hola, Â¿cÃ³mo estÃ¡s?"

# DeberÃ­as ver una respuesta del modelo
# Presiona Ctrl+D o escribe /bye para salir
```

### Test 2: Script de Python

```bash
# Desde el directorio raÃ­z del proyecto
python3 code/ollama/simple_chat.py

# DeberÃ­as ver:
# ğŸ¤– Chatbot Simple con Llama
# âœ“ Modelo cargado. Â¡Comencemos!
```

### Test 3: InformaciÃ³n del Sistema

```bash
python3 code/ollama/model_info.py --list

# DeberÃ­as ver la lista de modelos instalados
```

## ğŸ¯ Tus Primeros Pasos

### 1. Chatbot Interactivo (5 min)

```bash
cd code/ollama
python simple_chat.py

# Prueba preguntas como:
# - Â¿QuÃ© es Python?
# - Explica quÃ© es la IA
# - Escribe un haiku sobre programaciÃ³n
```

### 2. Streaming de Respuestas (5 min)

```bash
python streaming_response.py

# Observa cÃ³mo se genera el texto token por token
```

### 3. Sistema RAG BÃ¡sico (10 min)

```bash
cd ../rag
python simple_rag.py

# El script:
# 1. Carga documentos de ejemplo
# 2. Crea Ã­ndice de bÃºsqueda
# 3. Permite hacer preguntas sobre los documentos
```

### 4. Explorar la DocumentaciÃ³n (30 min)

```bash
# Abre en tu navegador o editor favorito
# Comienza con la portada
cat docs/00-portada.md

# O navega por GitHub:
# https://github.com/majorjuanjo/llama/tree/main/docs
```

## ğŸ“š Rutas de Aprendizaje

### Para Principiantes

1. âœ… [Portada](docs/00-portada.md) - Conoce el workshop
2. âœ… [CapÃ­tulo 0](docs/01-capitulo-0.md) - IntroducciÃ³n a IA y Llama
3. âœ… [CapÃ­tulo 2](docs/03-capitulo-2.md) - ConfiguraciÃ³n (ya la hiciste!)
4. âœ… [Glosario](docs/glosario.md) - TÃ©rminos clave
5. âœ… Experimenta con `code/ollama/simple_chat.py`

### Para Desarrolladores

1. âœ… [CapÃ­tulo 1](docs/02-capitulo-1.md) - Fundamentos tÃ©cnicos
2. âœ… [CapÃ­tulo 3](docs/04-capitulo-3.md) - ConstrucciÃ³n de apps
3. âœ… [CapÃ­tulo 4](docs/05-capitulo-4.md) - Casos avanzados
4. âœ… Explora ejemplos en `code/`
5. âœ… Lee [Anexos](docs/anexos.md) para troubleshooting

### Para Emprendedores

1. âœ… [Templates de Canvas](templates/canvas/)
2. âœ… [Plan 30-60-90](templates/30-60-90/)
3. âœ… [Casos de Uso](cases/)
4. âœ… [Biblioteca de Prompts](templates/prompts/)

## ğŸ”§ PersonalizaciÃ³n

### Cambiar de Modelo

```bash
# En cualquier script Python, cambia:
model = "llama3.2:3b"

# Por:
model = "llama3.1:8b"    # MÃ¡s potente
# o
model = "llama3.2:1b"    # MÃ¡s rÃ¡pido
```

### Ajustar ParÃ¡metros

```python
# En tus scripts, modifica:
response = ollama.chat(
    model='llama3.2:3b',
    messages=messages,
    options={
        'temperature': 0.7,  # Cambia entre 0.1 (preciso) y 1.5 (creativo)
        'top_p': 0.9,
        'top_k': 40
    }
)
```

## â“ Problemas Comunes

### "ollama: command not found"

**SoluciÃ³n**: Reinicia tu terminal despuÃ©s de instalar Ollama

```bash
# O especifica la ruta completa
/usr/local/bin/ollama --version  # macOS/Linux
```

### "Model not found"

**SoluciÃ³n**: Descarga el modelo primero

```bash
ollama pull llama3.2:3b
ollama list  # Verifica que se descargÃ³
```

### "Out of Memory"

**SoluciÃ³n**: Usa un modelo mÃ¡s pequeÃ±o

```bash
ollama pull llama3.2:1b  # Solo 1GB RAM necesaria
```

### "Module not found"

**SoluciÃ³n**: Instala las dependencias

```bash
pip install -r code/ollama/requirements.txt
```

### "Connection refused"

**SoluciÃ³n**: Inicia Ollama manualmente

```bash
# En una terminal separada
ollama serve

# En otra terminal, ejecuta tu script
python code/ollama/simple_chat.py
```

## ğŸ“ Obtener Ayuda

Si tienes problemas:

1. ğŸ“– Consulta [Troubleshooting en Anexos](docs/anexos.md#troubleshooting-avanzado)
2. ğŸ” Busca en [Issues](https://github.com/majorjuanjo/llama/issues)
3. ğŸ’¬ Pregunta en [Discussions](https://github.com/majorjuanjo/llama/discussions)
4. ğŸ“ Crea un [Issue nuevo](https://github.com/majorjuanjo/llama/issues/new/choose)

## ğŸ“ PrÃ³ximos Pasos

Una vez que hayas completado la configuraciÃ³n:

### Semana 1
- [ ] Completa CapÃ­tulos 0-2
- [ ] Ejecuta todos los ejemplos de `code/ollama/`
- [ ] Experimenta con diferentes prompts

### Semana 2
- [ ] Lee CapÃ­tulos 3-4
- [ ] Implementa tu primer sistema RAG
- [ ] Crea un chatbot personalizado

### Semana 3
- [ ] Explora casos de uso avanzados
- [ ] Integra Llama en un proyecto personal
- [ ] Comparte tu proyecto en la comunidad

### Mes 2
- [ ] Contribuye al repositorio
- [ ] Participa en discusiones
- [ ] Ayuda a otros usuarios

## ğŸŒŸ Consejos de Ã‰xito

1. **Comienza simple**: No intentes todo a la vez
2. **Practica diario**: 30 minutos al dÃ­a > 3 horas el fin de semana
3. **Experimenta**: Cambia parÃ¡metros y observa resultados
4. **Documenta**: Guarda tus hallazgos y experimentos
5. **Comparte**: Participa en la comunidad

## ğŸ¯ Checklist de Inicio

- [ ] Repositorio clonado
- [ ] Ollama instalado y funcionando
- [ ] Modelo descargado (llama3.2:3b o similar)
- [ ] Entorno virtual de Python creado
- [ ] Dependencias instaladas
- [ ] Chatbot simple ejecutado exitosamente
- [ ] DocumentaciÃ³n explorada
- [ ] Primeros ejemplos probados

## ğŸ‰ Â¡Listo!

Si completaste todos los pasos, estÃ¡s listo para comenzar tu viaje en el desarrollo de IA con Llama.

**Â¿QuÃ© sigue?**

ğŸ‘‰ [Ve al CapÃ­tulo 0](docs/01-capitulo-0.md) para comenzar el aprendizaje formal

ğŸ‘‰ [Explora los ejemplos](code/) para ver cÃ³digo en acciÃ³n

ğŸ‘‰ [Ãšnete a la comunidad](community/) para conectar con otros desarrolladores

---

**Â¿Necesitas ayuda?** No dudes en [abrir un issue](https://github.com/majorjuanjo/llama/issues/new/choose)

**Â¡Feliz aprendizaje!** ğŸš€
